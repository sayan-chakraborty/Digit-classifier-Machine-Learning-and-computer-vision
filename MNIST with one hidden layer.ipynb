{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 60000)\n",
      "(784, 60000)\n",
      "(10, 10000)\n",
      "(784, 10000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from keras.datasets import mnist #Keras is used only to get MNIST data\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "Y_train = Y_train.reshape(60000, 1).T \n",
    "b = np.zeros((60000, 10))\n",
    "b[np.arange(60000), Y_train] = 1\n",
    "Y_train = b.T #To convert to one hot matrix\n",
    "print(Y_train.shape)\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)/255 #Divided by 255 to normalize the input data\n",
    "X_train = X_train.reshape(X_train.shape[0], -1).T #We use -1 because numpy will itself figure out what -1 is by looking at length of tha array and the remaining dimensions\n",
    "print(X_train.shape)\n",
    "Y_test = Y_test.reshape(10000, 1).T\n",
    "b = np.zeros((10000, 10))\n",
    "b[np.arange(10000), Y_test] = 1\n",
    "Y_test = b.T\n",
    "print(Y_test.shape)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)/255\n",
    "X_test = X_test.reshape(X_test.shape[0], -1).T\n",
    "print(X_test.shape)\n",
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "learning_rate = 1\n",
    "m = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.19500900504763\n",
      "5.624256696556615\n",
      "4.818208313439643\n",
      "4.355769764245896\n",
      "3.995441274944555\n",
      "3.660420674357356\n",
      "3.3791301461862746\n",
      "3.145017331440061\n",
      "2.9539502169335523\n",
      "2.7813509439301116\n",
      "2.638283667112987\n",
      "2.507635458656162\n",
      "2.3898446255305275\n",
      "2.288901695868406\n",
      "2.191264091658651\n",
      "2.1118144249787956\n",
      "2.039753876747073\n",
      "1.9724514793340295\n",
      "1.9099060358622724\n",
      "1.8539123175046244\n",
      "1.803346448626223\n",
      "1.760033381261511\n",
      "1.713348580332609\n",
      "1.673459433133663\n",
      "1.6338175274905518\n",
      "1.6000441268745431\n",
      "1.5667953170673101\n",
      "1.5344782568261464\n",
      "1.5062379788487201\n",
      "1.4776906821450284\n",
      "1.4495469636274887\n",
      "1.42520647972225\n",
      "1.4033561733449877\n",
      "1.3779378551986654\n",
      "1.3551295025704806\n",
      "1.3338727604430745\n",
      "1.31257773979109\n",
      "1.2952123787838836\n",
      "1.2752506652348434\n",
      "1.2589320464242317\n",
      "1.2428112830221532\n",
      "1.2273986190410004\n",
      "1.21396638672503\n",
      "1.1982465726019824\n",
      "1.1850762849586922\n",
      "1.1705739662390426\n",
      "1.1583936314831031\n",
      "1.1465445597663317\n",
      "1.1334735739476127\n",
      "1.1233039213762577\n",
      "1.113478195208879\n",
      "1.104474792324908\n",
      "1.0944477612600152\n",
      "1.0843269744398452\n",
      "1.0740730691977434\n",
      "1.0674831251024337\n",
      "1.0583939252561396\n",
      "1.048203168892092\n",
      "1.0405060154961225\n",
      "1.0313413916512504\n",
      "1.0231752618284864\n",
      "1.0153031913441284\n",
      "1.0089095020083583\n",
      "1.0016212928628356\n",
      "0.99564981928969\n",
      "0.9871889145524103\n",
      "0.9795975100343491\n",
      "0.9731135861257788\n",
      "0.9662244941228211\n",
      "0.9598334962244741\n",
      "0.9549288151056092\n",
      "0.9504756452033591\n",
      "0.9439365365143295\n",
      "0.9373724796589769\n",
      "0.9331613095274324\n",
      "0.9275533554270899\n",
      "0.9212740336991112\n",
      "0.9163724233844306\n",
      "0.9120713405610796\n",
      "0.9070511583600753\n",
      "0.9014200396781067\n",
      "0.8959785886899861\n",
      "0.892576169410278\n",
      "0.8886013124940114\n",
      "0.884832126931373\n",
      "0.8791775281734326\n",
      "0.8757995142127999\n",
      "0.8720245323582398\n",
      "0.8680887812513289\n",
      "0.8638311904200594\n",
      "0.8593655033147855\n",
      "0.8551766895781214\n",
      "0.8531907672472943\n",
      "0.847832930501821\n",
      "0.8451709380146114\n",
      "0.841017841519801\n",
      "0.8368117272497785\n",
      "0.8338717147672374\n",
      "0.8290912971669354\n",
      "0.8271974419095598\n",
      "0.822525538140805\n",
      "0.8202820513919007\n",
      "0.8172884914209965\n",
      "0.8136300054436086\n",
      "0.8108994383126301\n",
      "0.8074320419156091\n",
      "0.8049223864300102\n",
      "0.8029229535069854\n",
      "0.798411785161368\n",
      "0.7956146035225027\n",
      "0.7942463082095587\n",
      "0.7926255033504307\n",
      "0.788436898621854\n",
      "0.7850031740427664\n",
      "0.7847826568770904\n",
      "0.7811524431868625\n",
      "0.779617281990121\n",
      "0.7757248752405727\n",
      "0.7728618551101037\n",
      "0.7703240338482137\n",
      "0.7674776111731728\n",
      "0.764419494633391\n",
      "0.7619275071425804\n",
      "0.7593907816386809\n",
      "0.7572433820565679\n",
      "0.7563450851904567\n",
      "0.7537565329740683\n",
      "0.7501846116636229\n",
      "0.7483722253553254\n",
      "0.7464743894552955\n",
      "0.7452995957864351\n",
      "0.7427196638920619\n",
      "0.7405204161581358\n",
      "0.7383958915108882\n",
      "0.7355934493953518\n",
      "0.7350984692934608\n",
      "0.7330462906817131\n",
      "0.7302886489550867\n",
      "0.7298143838556473\n",
      "0.7279084307653858\n",
      "0.7248981893762758\n",
      "0.723764544610602\n",
      "0.7209131234286106\n",
      "0.7200057089181228\n",
      "0.7176627309772285\n",
      "0.7152086755090077\n",
      "0.7154257042768072\n",
      "0.7122834876914087\n",
      "0.7110340669091275\n",
      "0.7093248707101956\n",
      "0.7065124715250685\n",
      "0.7061632741019674\n",
      "0.7033979708118485\n",
      "0.7014147377322131\n",
      "0.7016213300497087\n",
      "0.7004224023198358\n",
      "0.6990611712441525\n",
      "0.6965521043072503\n",
      "0.6949251247352434\n",
      "0.6943518704238131\n",
      "0.6927286194146469\n",
      "0.6919262435493351\n",
      "0.6914264426539071\n",
      "0.6900332347024856\n",
      "0.6876506146181965\n",
      "0.6869301985768405\n",
      "0.6845577006100533\n",
      "0.6836690683421449\n",
      "0.6822785540451584\n",
      "0.6813874070384445\n",
      "0.6815504154562382\n",
      "0.6784887852380843\n",
      "0.6781823328459268\n",
      "0.6757417193904011\n",
      "0.6745219308891783\n",
      "0.6714012843293313\n",
      "0.6699152952188949\n",
      "0.6700094924659539\n",
      "0.6681616911035817\n",
      "0.6669691715945857\n",
      "0.6665326725692095\n",
      "0.6663897198580038\n",
      "0.6638707395552136\n",
      "0.662299212204635\n",
      "0.6626437034845939\n",
      "0.6608001115635735\n",
      "0.6609676508328831\n",
      "0.6592570702262281\n",
      "0.6567028166674549\n",
      "0.6570180599881164\n",
      "0.6547225979296368\n",
      "0.6519367339714626\n",
      "0.6538821946530812\n",
      "0.6517794997598612\n",
      "0.6508696553281336\n",
      "0.6503317650374831\n",
      "0.6482289492873451\n",
      "0.6459504246433062\n",
      "0.645632349574033\n",
      "0.6436842146298741\n",
      "0.6445697931608072\n",
      "0.6434479610262694\n",
      "0.6422072043683167\n",
      "0.6395336271756324\n",
      "0.6398758051804505\n",
      "0.6374298547420919\n",
      "0.6373099270635898\n",
      "0.6378147822845974\n",
      "0.6342298458237825\n",
      "0.6325968537886495\n",
      "0.6329391961672298\n",
      "0.6307740622024995\n",
      "0.6294969989432422\n",
      "0.6278859703943297\n",
      "0.6285094706468487\n",
      "0.6274746537295302\n",
      "0.627004363847279\n",
      "0.6268657549345669\n",
      "0.6251112746696567\n",
      "0.6254292009257041\n",
      "0.6225415377441882\n",
      "0.6220244290019289\n",
      "0.6228098260789032\n",
      "0.6212112261602788\n",
      "0.6194270783203935\n",
      "0.618039101028735\n",
      "0.6161440106678633\n",
      "0.6152679100630949\n",
      "0.6135043135823929\n",
      "0.6133209188822382\n",
      "0.6135246669313019\n",
      "0.6131546969811101\n",
      "0.6120029196633839\n",
      "0.6111488937470154\n",
      "0.6106220169072392\n",
      "0.6087366660007414\n",
      "0.6086928624519766\n",
      "0.6072567256943427\n",
      "0.6074988194265227\n",
      "0.606294545444142\n",
      "0.6047071805105233\n",
      "0.6037596049831144\n",
      "0.6036925161714053\n",
      "0.6022551479947611\n",
      "0.6028094414921009\n",
      "0.6010047470190387\n",
      "0.6009455572538444\n",
      "0.6015532450955271\n",
      "0.6000884426594729\n",
      "0.5987074617244971\n",
      "0.5981024506017804\n",
      "0.5981923394313877\n",
      "0.5972426895646249\n",
      "0.5970435789532854\n",
      "0.5961296487993556\n",
      "0.5958891792066441\n",
      "0.5954037974744953\n",
      "0.5944765541970433\n",
      "0.5927801982544104\n",
      "0.5917417231963935\n",
      "0.5915884004251504\n",
      "0.5923626782603856\n",
      "0.5895975047760128\n",
      "0.5886429029709338\n",
      "0.5896724160238556\n",
      "0.586797166327129\n",
      "0.5886092282709294\n",
      "0.5863770746357575\n",
      "0.5851255600189773\n",
      "0.585580632107723\n",
      "0.5831694629131573\n",
      "0.5838486394706522\n",
      "0.5834308923580331\n",
      "0.5817849224462992\n",
      "0.5813708153715531\n",
      "0.5801981116177984\n",
      "0.5804496563720584\n",
      "0.580187699254876\n",
      "0.5783424221027818\n",
      "0.5773629115936635\n",
      "0.5762665993742679\n",
      "0.5758893590571282\n",
      "0.5767370274261469\n",
      "0.5779310473255884\n",
      "0.5759440013278325\n",
      "0.5752697626434558\n",
      "0.5736016494356109\n",
      "0.5721208030040594\n",
      "0.5717830315038944\n",
      "0.5716018923269228\n",
      "0.5736827931702493\n",
      "0.5720477174427154\n",
      "0.5702566979280798\n",
      "0.5700984077705143\n",
      "0.5690540489922379\n",
      "0.5674326126028634\n",
      "0.5680768982092183\n",
      "0.5688611986589784\n",
      "0.5661145826638725\n",
      "0.5664801590749129\n",
      "0.5648626891756623\n",
      "0.5663716812898035\n",
      "0.5647746411654798\n",
      "0.5632548836421409\n",
      "0.562350068253183\n",
      "0.5629804753100127\n",
      "0.5625818911719637\n",
      "0.5622525220162957\n",
      "0.5617650855413143\n",
      "0.5612072248760547\n",
      "0.5617918737231082\n",
      "0.560211441210878\n",
      "0.5603539607887688\n",
      "0.5588003290803474\n",
      "0.5586437638622999\n",
      "0.5571960089522915\n",
      "0.5563338940338477\n",
      "0.5562856253120411\n",
      "0.5554730662990165\n",
      "0.5564627306256429\n",
      "0.5538138710394184\n",
      "0.553963429378313\n",
      "0.5527378685635894\n",
      "0.5527841566620673\n",
      "0.5540873544029462\n",
      "0.5525742033019198\n",
      "0.5515163658655695\n",
      "0.5518283841549252\n",
      "0.5510958018671223\n",
      "0.5514689312158225\n",
      "0.5493329753349858\n",
      "0.5485854185684692\n",
      "0.5482710814669433\n",
      "0.547945854622952\n",
      "0.5466915463145696\n",
      "0.5470373810001904\n",
      "0.5476303739171591\n",
      "0.5473874410391815\n",
      "0.5451730316570191\n",
      "0.5454592206919354\n",
      "0.5449957942777159\n",
      "0.5453070949834482\n",
      "0.5455140840987024\n",
      "0.543192552696636\n",
      "0.5430909978756302\n",
      "0.5419457557668015\n",
      "0.5428136235758664\n",
      "0.5420716531561204\n",
      "0.5408243255452506\n",
      "0.5399536907107889\n",
      "0.5394770241233354\n",
      "0.5387354489619163\n",
      "0.5392315767550652\n",
      "0.5396391146015128\n",
      "0.5382859931360648\n",
      "0.5393137026891344\n",
      "0.5390448443628754\n",
      "0.5372863722640799\n",
      "0.5370886167313456\n",
      "0.536567303616795\n",
      "0.5367662194261316\n",
      "0.536994050504189\n",
      "0.5348069729569815\n",
      "0.5351510479612539\n",
      "0.53522736834756\n",
      "0.5348755906747151\n",
      "0.5331505749019142\n",
      "0.533718385805227\n",
      "0.5335914719617516\n",
      "0.534654782417024\n",
      "0.5322230792515799\n",
      "0.532579435215672\n",
      "0.5317619267898588\n",
      "0.5314672581534275\n",
      "0.5305823168928814\n",
      "0.5324883870386931\n",
      "0.5304333433923354\n",
      "0.5292845455912045\n",
      "0.5284577686564128\n",
      "0.5280736249663834\n",
      "0.5273152491256112\n",
      "0.5272495069293575\n",
      "0.528519566466992\n",
      "0.5286490958019299\n",
      "0.5266125676932408\n",
      "0.5257421080073258\n",
      "0.5258078849173579\n",
      "0.5246509534358129\n",
      "0.5247018716298466\n",
      "0.5249154657933354\n",
      "0.5243694149652531\n",
      "0.5235476374558904\n",
      "0.523559181231038\n",
      "0.5239376832899361\n",
      "0.5234222564559625\n",
      "0.5220663209305175\n",
      "0.5226383095819778\n",
      "0.5221971221922601\n",
      "0.5213704166063212\n",
      "0.52065032583621\n",
      "0.5213695601948305\n",
      "0.5220106887185555\n",
      "0.5216848969343705\n",
      "0.5207513392298921\n",
      "0.5195788496006708\n",
      "0.5187363641011244\n",
      "0.5176015410796801\n",
      "0.5169377410417818\n",
      "0.5172571074195523\n",
      "0.516036426508705\n",
      "0.5171700861215849\n",
      "0.5163350525838627\n",
      "0.5159329136823243\n",
      "0.5161551959654515\n",
      "0.51457068882971\n",
      "0.5150888398845657\n",
      "0.5152251121194148\n",
      "0.5139655470697195\n",
      "0.5160266678241032\n",
      "0.5149771273936996\n",
      "0.5126440408092825\n",
      "0.5125646741120122\n",
      "0.5130821326698944\n",
      "0.5128492649147605\n",
      "0.5129138304564194\n",
      "0.512382069524976\n",
      "0.5122833973546518\n",
      "0.511675929356908\n",
      "0.5108189644695988\n",
      "0.51148170552568\n",
      "0.509438142731373\n",
      "0.5095035717719903\n",
      "0.5093919544372393\n",
      "0.5100520760870052\n",
      "0.5108793366286084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5095179318370242\n",
      "0.5096859612283495\n",
      "0.5081549771541164\n",
      "0.5087888191300499\n",
      "0.5099479944997266\n",
      "0.5084775598893226\n",
      "0.5071989698255706\n",
      "0.506767596191725\n",
      "0.5065704067606535\n",
      "0.5063164003519872\n",
      "0.5073101916820923\n",
      "0.5057186869944321\n",
      "0.5050653722993219\n",
      "0.5051317690145832\n",
      "0.5055701524726434\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-76fd7886a58b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdZ2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mdA1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdZ2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mdZ1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdA1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mdW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdZ1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mdb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdZ1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-c02eb4f4f0c9>\u001b[0m in \u001b[0;36msigmoid\u001b[1;34m(z)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W1 = np.random.randn(64, 784) * 0.01 #0.01 is multiplied to make gradient descent faster\n",
    "#W's are initialized randomly in order to break symmetry\n",
    "b1 = np.zeros((64, 1))\n",
    "W2 = np.random.randn(10, 64) * 0.01\n",
    "b2 = np.zeros((10, 1))\n",
    "for i in range(2000):\n",
    "    #Forward propagation\n",
    "    Z1 = np.matmul(W1, X_train) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.matmul(W2, A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    cost = np.sum(np.multiply(np.log(A2), Y_train))/ (-60000)\n",
    "    print(cost)\n",
    "    #Backward propagation\n",
    "    dZ2 = A2 - Y_train\n",
    "    dW2 = (1./60000) * np.matmul(dZ2, A1.T)\n",
    "    db2 = (1./60000) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dA1 = np.matmul(W2.T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
    "    dW1 = (1./m) * np.matmul(dZ1, X_train.T)\n",
    "    db1 = (1./m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 82.92 %.\n"
     ]
    }
   ],
   "source": [
    "#Finding out the accuracy\n",
    "Z1 = np.matmul(W1, X_test) + b1\n",
    "A1 = sigmoid(Z1)\n",
    "Z2 = np.matmul(W2, A1) + b2\n",
    "A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "predictions = np.argmax(A2, axis=0) #np.argmax axis = 0 return the values of the maximum indices along the columns\n",
    "labels = np.argmax(Y_test, axis=0)\n",
    "p = np.zeros((10000,))\n",
    "for i in range(10000):\n",
    "    if predictions[i] == labels[i]:\n",
    "        p[i] = 1\n",
    "    else:\n",
    "        p[i] = 0\n",
    "count = 0\n",
    "for i in range(10000):\n",
    "    if p[i] == 1:\n",
    "        count = count + 1\n",
    "accuracy = count / 100\n",
    "print('The accuracy is ' + str(accuracy) + ' %.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
